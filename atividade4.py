# -*- coding: utf-8 -*-
"""Atividade4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18ehsWlikkL4zztxNtbaPUmCCZ91QeM7p
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn import tree
import pandas as pd

# Link do dataset importado, coloquei no meu google pessoal e exportei.
url = "https://docs.google.com/spreadsheets/d/1X3Hm2IM3hWdyDbSNrqkO2Os0H-jXek-d7Yy3WXQXZrQ/export?format=csv&gid=0"

df = pd.read_csv(url)

# Definindo as labels(classes) do eixo y do treino
diagnosis = {'M': 0, 'B': 1}
df['diagnosis'] = df['diagnosis'].map(diagnosis)
diagnosis_list = ['M', 'B']

# O data set possui se, que é para erro padrão, worst para o pior caso observado.
# Inicialmente, utilizarei apenas o mean para treinar o dataset.
# Aqui, eu faço um dataframe com todas as colunas que já possuem mean, ou seja, a média dos dados.
X = df.filter(like="mean")
y = df['diagnosis']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Utilizando os valores de treino e de teste na ávore de decisão
clf = tree.DecisionTreeClassifier(random_state=42)
clf = clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Aqui, eu peguei a acurácia em formato de float e formatei ela para só duas casas
# decimais, e coloquei no formato brasileiro com , ao invés de .
# Transformando em uma porcentagem mais "legível"
print("Acurácia: {:.2f}%".format(accuracy * 100).replace('.', ','))

# Trocando a seed (random_state) para 50, com o objetivo de testar novamente os resultados

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)

clf = tree.DecisionTreeClassifier(random_state=50)
clf = clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("Acurácia: {:.2f}%".format(accuracy * 100).replace('.', ','))

# A acurácia mudou em 7% de 95,61% para 87,72%, indicando que da forma que treinei o dataset, os dados estão muito voláteis
# a mudar sua acurácia de predição.
# A seed influencia nisso, pois ela é um valor aleatório para sempre garantir os mesmos resultados, quando ela for utilizada
# Então, se eu replicar 42 ou 50, os valores dos resultados sempre serão os mesmos

# Aqui eu fiz um for com base no array de colunas do X, já filtrados com "mean"
# A partir disso, eu faço um for para cada uma das colunas, perguntando
# O valor e armazenando em um array
# Depois irei utilizar esse array com base na árvore já treinada
# Para fazer com que ele me diga se é M (Maligno) = 0, ou B (Benigno) = 1
colunas = X.columns

entrada_usuario = []

for coluna in colunas:
    while True:
        try:
            valor = float(input(f"Digite o valor para {coluna}: "))
            entrada_usuario.append(valor)
            break
        except ValueError:
            print("Por favor, digite um número válido.")

# Aqui eu transformo a lista em data frame, para não acusar erro.
entrada_usuario_df = pd.DataFrame([entrada_usuario], columns=colunas)

predicao = clf.predict(entrada_usuario_df)

resultado = "Maligno (0)" if predicao[0] == 0 else "Benigno (1)"

print("A previsão do modelo é:", resultado)

# O modelo previu que era maligno, após inserir os dados da segunda linha
# Com base nos dados que continham _mean no csv

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

# Aqui aumentei o tamanhho da figura e da fonte, por conta do tamanho da árvore ela ficava
# ilegível, então expandi ela.
plt.figure(figsize=(20, 12))
plot_tree(clf, feature_names=X.columns, class_names=[str(i) for i in diagnosis_list], filled=True, rounded=True,proportion=True, fontsize=10)
plt.show()

# Agora, irei mudar o max_depth, colocando como 4, para vermos quanto a acurácia irá ficar
# Coloquei em 4 para forçar que ela não decore o dataset, e tente generalizar
# Os dados conforme a inserção, para predizer corretamente novos dados.
clf = tree.DecisionTreeClassifier(max_depth=4, random_state=50)
clf = clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("Acurácia: {:.2f}%".format(accuracy * 100).replace('.', ','))

# A acurácia aumentou em aproximadamente 4%~
# Indo de 87,72% para 92,11% no random_state 50
# O max_depth influencia, pois força a não decorar o dataset, e com valores
# novos, ela consegue generalizar os dados, não alucinando ou perdendo sua
# capacidade de predição

# Aqui vizualizaremos novamente a árvore, agora para o max_depth = 4
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20, 12))
plot_tree(clf, feature_names=X.columns, class_names=[str(i) for i in diagnosis_list], filled=True, rounded=True,proportion=True, fontsize=10)
plt.show()

# Aqui geramos a matriz de confusão, e vamos exibí-la de forma visual
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_pred, labels=[0, 1])

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Maligno (0)", "Benigno (1)"])
disp.plot(cmap=plt.cm.Blues)
plt.show()

# O que foi analisado:
# A matriz de confusão mostra que ela previu corretamente o maligno 34 vezes
# E o benigno 71 vezes. Porém, ela confundiu 5 vezes o Maligno com benigno
# E também confundiu o benigno com maligno 4 vezes.
# Conclusão:
# Os resultados foram condizentes, talvez se adicionassemos os valores de
# Erro padrão e de pior valor possível, a predição seria mais adequada.
# Porém, também poderia gerar confusão, pois ela teria muitos parâmetros para
# Analisar, e isso dificultaria sua predição correta, o ideal seria um equilíbrio
# Juntando parâmetros que podem se juntar, e fazendo uma limpeza profunda
# dos dados.